__author__ = 'sharelison'
import requests
import os
from requests.exceptions import ConnectionError
from bs4 import BeautifulSoup
from PcPart import PcPart

pcParts = []
pcParts.append(PcPart('http://www.alternate.nl/html/configurator/builder/structure/page.html?cmd=search&componentType=required&className=powerSupply&activeClassName=powerSupply&kind=pcBuilder&size=500#listingResult',
                      'voedingAlternate.txt', [['Vermogen', 'Totaal', 0, ":"], ['Bouwvorm', 0, ":"]]))
pcParts.append(PcPart('http://www.alternate.nl/html/configurator/builder/structure/page.html?cmd=search&componentType=required&className=cpu&activeClassName=cpu&kind=pcBuilder&size=500#listingResult',
                      "processorsAlternate.txt", [['Socket', 0, ":"]]))
pcParts.append(PcPart('http://www.alternate.nl/html/configurator/builder/structure/page.html?cmd=search&componentType=required&className=ram&activeClassName=ram&kind=pcBuilder&size=500#listingResult',
                     "geheugenAlternate.txt", [['Type', 0, ":"], ['Module', 0, 1]]))
pcParts.append(PcPart('http://www.alternate.nl/html/configurator/builder/structure/page.html?cmd=search&componentType=required&className=harddiskSATA&activeClassName=harddisk&kind=pcBuilder&size=500#listingResult',
                      "harddiskAlternate.txt", "none"))
pcParts.append(PcPart('http://www.alternate.nl/html/configurator/builder/structure/page.html?cmd=search&componentType=required&className=graphicscardPCIe&activeClassName=graphicscard&kind=pcBuilder&size=500#listingResult',
                      "grafischKaartAlternate.txt", [['Geheugen', 'Type', 0, ":"]]))
pcParts.append(PcPart('http://www.alternate.nl/html/configurator/builder/structure/page.html?cmd=search&componentType=required&className=pccase&activeClassName=pccase&kind=pcBuilder&size=500#listingResult',
                      "behuizingAlternate.txt", [['PSU', 8, ":"]]))
pcParts.append(PcPart("http://www.alternate.nl/html/configurator/builder/structure/page.html?cmd=search&componentType=required&className=mainboard&activeClassName=mainboard&kind=pcBuilder&size=500#listingResult",
                      "moederboardAlternate.txt", [['Geheugen', 'Geheugen socket', 0, 1],
                                                   ['Geheugen', 'Type geheugen', 0, ":"], ['Formfactor', 0, ":"], ['Socket', 0, ":"]]))
seperator = '>>>'

def crawl(givenUrl, filename):
    completeName = os.path.join(filename)
    file = open(completeName, 'w')
    url = givenUrl
    source_code = requests.get(url)
    text = source_code.text
    soup = BeautifulSoup(text, from_encoding='utf-8')

    for link in soup.findAll('a', {'class': 'productLink'}):
         href = "http://www.alternate.nl" + link.get('href')
         try:
            get_single_item_data(href, file)
         except ConnectionError:
            ""

def get_single_item_data(item_url, file1):
    website = str('http://www.alternate.nl')
    source_code = requests.get(item_url)
    text = source_code.text
    soup = BeautifulSoup(text, from_encoding='utf-8')

    def getSpecificInfo(info):
     returninfo = []
     for information in info:
        table = soup.find_all('table', {'class', 'techDataTable'})
        for table2 in table:
            for td in table2.find_all('td', {'class', 'techDataCol1'}):
                if td.text == information[0]:
                   tr = td.parent
                   if 'Geheugen' in information[0] or 'Vermogen' in information[0]:
                    table3 = tr.find_all('table')
                    for table4 in table3:
                        for td2 in table4.find_all('td', {'class': 'techDataSubCol techDataSubColDescription'}):
                            if td2.text == information[1]:
                                tr2 = td2.parent
                                t = 0
                                for td3 in tr2.find_all('td', {'class': 'techDataSubCol techDataSubColValue'}):
                                  if t > 0:
                                    break
                                  else:
                                        if information[3] == ":":
                                            returninfo.append(td3.text[information[2]:])
                                        else:
                                            returninfo.append(td3.text[information[2]:information[3]])
                                  t = t + 1
                   else:
                        for nextTd in tr.find_all('td', {'class', 'techDataCol2'}):
                            if information[2] == ":":
                             returninfo.append(nextTd.text[information[1]:])
                            else:
                             returninfo.append(nextTd.text[information[1]:information[2]])
     return returninfo

    #Product link pakken
    for link in soup.findAll('span'):
        if link.parent.name == 'p':
            try:
                file1.write('~~~' + link['content'] + seperator)
            except Exception, e:
                print str(e)

    #Product naam pakken
    title = soup.find_all('div', {"class": "productNameContainer"})
    for title2 in title:
        realTitle = title2.find_all('h1')
        for realTitle2 in realTitle:
            productName = realTitle2.text
            print productName.encode('utf-8')
            try:
              file1.write(productName.encode('utf-8'))
            except Exception, e:
              print(str(e))

    #Product omschrijving pakken
    desc = soup.find_all('div', {'class': 'description'})
    for desc1 in desc:
     description = desc1.find_all('p')
     for desc2 in description:
        try:
         if 'Art-Nr' not in desc2.text:
            productDesc = desc2.text
            file1.write(seperator + productDesc.encode('utf-8'))
        except Exception, e:
         print str(e)

    #Product photo pakken.
    photoParent = soup.find_all('a', {"class": "picture loupe lightboxMediaJS"})
    for photoElement in photoParent:
       for photoSrc in photoElement.find_all("img"):
        photo = photoSrc.get('src')
        try:
          file1.write('www.alternate.nl' + photo.encode('utf-8'))
        except Exception, e:
          print str(e)

    #Als er specificaties moet gepakt worden per pc onderdeel methode getSpecificInfo wordt aangeroepen. Anders product schrijven naar    textbestand
    if pcPart.specs != "none":
        information = getSpecificInfo(pcPart.specs)
        for allSpecs in information:
            file1.write(seperator + allSpecs.encode('utf-8'))
        file1.write(seperator + item_url + seperator + website + '')
    else:
        file1.write(seperator + item_url + seperator + website + '')

teller = 0        
while teller < len(pcParts):
    try:
        pcPart = pcParts[teller]
        crawl(pcPart.link, pcPart.name)
    except ConnectionError, e:
        ""
    teller = teller + 1
